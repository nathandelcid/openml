{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7af07d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "import numpy as np\n",
    "from log_reg import LogisticRegression\n",
    "from min_max_scaler import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af587dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.375     , 0.25      , 0.28205128, 0.00765098, 0.        ,\n",
       "       0.        , 0.        , 0.5       , 0.375     , 0.1380531 ,\n",
       "       0.55299539, 0.53043478])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "binary_data = data.BinaryPrices()\n",
    "X_train = binary_data.X_train\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "y_train = binary_data.y_train\n",
    "\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048bce9a",
   "metadata": {},
   "source": [
    "# Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82fc045b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector:  [1.         0.375      0.25       0.28205128 0.00765098 0.\n",
      " 0.         0.         0.5        0.375      0.1380531  0.55299539\n",
      " 0.53043478]\n",
      "Weight vector:  [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "Score:  0.30855273372347336\n"
     ]
    }
   ],
   "source": [
    "x = binary_data.X_train[0]\n",
    "x = np.insert(x, 0, 1)\n",
    "\n",
    "w = np.ones(x.shape) / x.shape\n",
    "\n",
    "print(\"Feature vector: \", x)\n",
    "print(\"Weight vector: \", w)\n",
    "\n",
    "z = np.sum(w * x, axis=-1) \n",
    "print(\"Score: \", z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "798dd319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30855273372347336\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "z = log_reg.score(x)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e94d7e6",
   "metadata": {},
   "source": [
    "# Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d556a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5765319605995369\n"
     ]
    }
   ],
   "source": [
    "p = log_reg.sigmoid(x)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6f4537",
   "metadata": {},
   "source": [
    "# Negative Log Likelihood\n",
    "\n",
    "\n",
    "\n",
    "When training logistic regression models, are goal is to find the **weights $w$** that make our model's predictions most consistent with the observed data\n",
    "\n",
    "$$p(y_i = 1 | x_i ; w) = \\sigma(w^T x)$$\n",
    "\n",
    "- **Choose weights** that make all **observed labels $y_i$** as likely as the possible given input $x_i$\n",
    "\n",
    "**Likelihood:** Product of all the probabilities that the model assigns to each observed outcome\n",
    "\n",
    "$$L(w) = \\prod_{i=1}^N p(y_i | x_i ; w)$$\n",
    "\n",
    "For logistic regression, this becomes\n",
    "\n",
    "$$L(w) = \\prod_{i=1}^{N}[\\sigma(w^T x)]^{y_i} \\cdot [1-\\sigma(w^T x)]^{1-y_i}$$\n",
    "\n",
    "Since products are messy, we take the logarithm to turn the products into sums\n",
    "\n",
    "$$\\log L(w) = \\sum_{i=1}^N [y_i \\log(\\sigma(w^T x_i)) + (1-y_i)\\log(1- \\sigma(w^T x_i))]$$\n",
    "- We do this because its easier to take the derivates of sums rather than products\n",
    "\n",
    "Our goal is to **minimize** the loss function, so we flip the sign and get\n",
    "\n",
    "\\begin{align}\n",
    "\\textrm{NLL}(\\mathbf{w}) = -\\frac{1}{N}\\sum_{i=1}^N \\left[y_i \\log \\sigma(\\mathbf{w}^T{\\mathbf{x_i}}) + (1-y_i)\\log(1 - \\sigma(\\mathbf{w}^T\\mathbf{x_i}))\\right]\n",
    "\\end{align}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d90cc61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data:\n",
      "[1.         0.375      0.25       0.28205128 0.00765098 0.\n",
      " 0.         0.         0.5        0.375      0.1380531  0.55299539\n",
      " 0.53043478]\n",
      "[1.         0.5        0.41666667 0.36467236 0.01287321 0.25\n",
      " 1.         1.         1.         0.5        0.24424779 0.5437788\n",
      " 0.24347826]\n",
      "[1.         0.75       0.70833333 0.93447293 0.01525816 1.\n",
      " 0.         1.         0.75       1.         0.86902655 0.76036866\n",
      " 0.86086957]\n",
      "[1.         0.375      0.33333333 0.1965812  0.01091513 0.\n",
      " 0.         0.         0.5        0.5        0.24424779 0.\n",
      " 0.77391304]\n",
      "[1.         0.25       0.16666667 0.17378917 0.01364646 0.\n",
      " 0.         0.         0.75       0.375      0.12743363 0.23041475\n",
      " 0.46956522]\n",
      "[1.         0.125      0.16666667 0.03133903 0.00575097 0.\n",
      " 0.         0.         0.5        0.125      0.03893805 0.\n",
      " 0.33913043]\n",
      "[1.         0.375      0.33333333 0.16951567 0.01456845 0.\n",
      " 0.         0.         0.75       0.375      0.21061947 0.\n",
      " 0.74782609]\n",
      "[1.         0.375      0.58333333 0.49145299 0.00317246 0.5\n",
      " 0.         0.         0.5        0.875      0.41415929 0.51152074\n",
      " 0.88695652]\n",
      "[1.         0.5        0.75       0.55270655 0.0194983  0.5\n",
      " 0.         0.         0.5        0.875      0.68672566 0.\n",
      " 0.73913043]\n",
      "[1.         0.625      0.29166667 0.13960114 0.00444796 0.\n",
      " 0.         0.         0.5        0.125      0.17345133 0.\n",
      " 0.13913043]\n",
      "\n",
      "\n",
      "Observed data:\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "\n",
      "\n",
      "Probabilities:\n",
      "0.5765319605995369\n",
      "0.6328088699420288\n",
      "0.6774721967602195\n",
      "0.5750815658173204\n",
      "0.5679711227866563\n",
      "0.544722946042062\n",
      "0.5758684582153296\n",
      "0.6159406437877168\n",
      "0.6156215250250984\n",
      "0.5574053249265434\n",
      "\n",
      "\n",
      "Likelihood:\n",
      "0.0004378773036123921\n"
     ]
    }
   ],
   "source": [
    "X_train = binary_data.X_train[0:10]\n",
    "X_train = np.concatenate([np.ones((X_train.shape[0], 1)), X_train], axis=1)\n",
    "y_train = binary_data.y_train[0:10]\n",
    "probs = []\n",
    "print(\"Sample data:\")\n",
    "for i in range(len(X_train)):\n",
    "    print(X_train[i])\n",
    "print(\"\\n\")\n",
    "print(\"Observed data:\")\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    print(y_train[i])\n",
    "print(\"\\n\")\n",
    "print(\"Probabilities:\")\n",
    "for i in range(len(X_train)):\n",
    "    x = X_train[i]\n",
    "    y = y_train[i]\n",
    "    z = log_reg.score(x)\n",
    "    p = log_reg.sigmoid(x)\n",
    "    probs.append(p)\n",
    "    print(p)\n",
    "print(\"\\n\")\n",
    "likelihood = np.prod([probs[i] ** y_train[i] * (1 - probs[i]) ** (1 - y_train[i]) for i in range(len(probs))])\n",
    "print(\"Likelihood:\")\n",
    "print(likelihood)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0235fcd3",
   "metadata": {},
   "source": [
    "# Gradient\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\textrm{NLL}}{\\partial \\mathbf{w}} = \\frac{1}{N} \\sum_i \\left[\\sigma(\\mathbf{w}^T\\mathbf{x}_i)-y_i)\\right]\\mathbf{x}_i\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efd28df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(5.996135824629257)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient = np.sum([probs[i] - y_train[i] * X_train[i] for i in range(len(probs))]) / len(X_train)\n",
    "gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6213592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09394246, 0.06945643, 0.10653699, 0.12545962, 0.00215478,\n",
       "       0.14514555, 0.06328089, 0.13102811, 0.09914447, 0.16419397,\n",
       "       0.11474697, 0.10709961, 0.09187016])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad = sum((probs[i] - y_train[i]) * X_train[i] for i in range(len(probs))) / len(X_train)\n",
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f906a047",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for /: 'list' and 'int'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83575334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
